Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 8
Rules claiming more threads will be scaled down.
Job stats:
job                 count    min threads    max threads
----------------  -------  -------------  -------------
DiamondAlignment        1              4              4
FilterFastaSACRA        1              4              4
FilteringDIAMOND        1              4              4
ProwlerTrim             1              4              4
SACRAcall               1              4              4
StatisticsToHTML        1              4              4
all                     1              1              1
total                   7              1              4

Select jobs to execute...

[Fri May 12 23:44:42 2023]
rule ProwlerTrim:
    input: PorechopABI/fastq_runid_211/fastq_runid_211PoreChopReads.fastq
    output: ProwlerProcessed/fastq_runid_211/fastq_runid_211PoreChopReadsTrimLT-U0-D7W100L100R0.fasta
    jobid: 2
    reason: Forced execution
    threads: 4
    resources: tmpdir=/tmp

Terminating processes on user request, this might take some time.
[Fri May 12 23:44:58 2023]
Error in rule ProwlerTrim:
    jobid: 2
    input: PorechopABI/fastq_runid_211/fastq_runid_211PoreChopReads.fastq
    output: ProwlerProcessed/fastq_runid_211/fastq_runid_211PoreChopReadsTrimLT-U0-D7W100L100R0.fasta
    shell:
        python3 scripts/TrimmerLarge.py -f PorechopABI/fastq_runid_211/fastq_runid_211PoreChopReads.fastq -i PorechopABI/fastq_runid_211/ -o ProwlerProcessed/fastq_runid_211/ -m D -c LT -g U0 -q 7 -w 100 -l 100 -d 0 -r '.fasta'
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

Complete log: .snakemake/log/2023-05-12T234438.770846.snakemake.log
