Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 8
Rules claiming more threads will be scaled down.
Job stats:
job                 count    min threads    max threads
----------------  -------  -------------  -------------
ProwlerTrim             1              1              1
SACRAcall               1              1              1
StatisticsToHTML        1              1              1
all                     1              1              1
total                   4              1              1

Select jobs to execute...

[Wed May  3 12:42:08 2023]
rule ProwlerTrim:
    input: PorechopABI/PoreChopReads.fastq
    output: ProwlerProcessed/PoreChopReadsTrimLT-U0-D7W100L100R0.fasta
    jobid: 2
    reason: Forced execution
    resources: tmpdir=/tmp

[Wed May  3 12:42:10 2023]
Finished job 2.
1 of 4 steps (25%) done
Select jobs to execute...

[Wed May  3 12:42:10 2023]
rule SACRAcall:
    input: ProwlerProcessed/PoreChopReadsTrimLT-U0-D7W100L100R0.fasta
    output: SACRAResults/SacraResults.fasta
    jobid: 3
    reason: Input files updated by another job: ProwlerProcessed/PoreChopReadsTrimLT-U0-D7W100L100R0.fasta
    resources: tmpdir=/tmp

Activating conda environment: .snakemake/conda/f655fa01c3df1c861f181a2fd0ee0401_
Terminating processes on user request, this might take some time.
[Wed May  3 12:42:34 2023]
Error in rule SACRAcall:
    jobid: 3
    input: ProwlerProcessed/PoreChopReadsTrimLT-U0-D7W100L100R0.fasta
    output: SACRAResults/SacraResults.fasta
    conda-env: /home/guillaume/ChimereNanoporePipeline/.snakemake/conda/f655fa01c3df1c861f181a2fd0ee0401_
    shell:
        scripts/SACRA.sh -i ProwlerProcessed/PoreChopReadsTrimLT-U0-D7W100L100R0.fasta -p SACRAResults/SacraResults.fasta -t 6 -c config_sacra.yml
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

Complete log: .snakemake/log/2023-05-03T124207.827810.snakemake.log
