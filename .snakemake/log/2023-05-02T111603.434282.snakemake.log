The flag 'directory' used in rule all is only valid for outputs, not inputs.
Building DAG of jobs...
Creating conda environment envs/sacra.yaml...
Downloading and installing remote packages.
Environment for /home/guillaume/ChimereNanoporePipeline/envs/sacra.yaml created (location: .snakemake/conda/f655fa01c3df1c861f181a2fd0ee0401_)
Using shell: /usr/bin/bash
Provided cores: 8
Rules claiming more threads will be scaled down.
Job stats:
job           count    min threads    max threads
----------  -------  -------------  -------------
SACRA_call        1              1              1
all               1              1              1
total             2              1              1

Select jobs to execute...

[Tue May  2 11:16:30 2023]
rule SACRA_call:
    input: scripts, ProwlerProcessed/Output_readsTrimLT-U0-D7W100L100R0.fasta
    output: sacra_reads.fasta
    jobid: 4
    reason: Updated input files: ProwlerProcessed/Output_readsTrimLT-U0-D7W100L100R0.fasta, scripts
    resources: tmpdir=/tmp

Activating conda environment: .snakemake/conda/f655fa01c3df1c861f181a2fd0ee0401_
[Tue May  2 11:19:43 2023]
Finished job 4.
1 of 2 steps (50%) done
Select jobs to execute...

[Tue May  2 11:19:43 2023]
localrule all:
    input: reports/Results.html, reports/Statistics.txt, ProwlerProcessed, sacra_reads.fasta
    jobid: 0
    reason: Input files updated by another job: sacra_reads.fasta
    resources: tmpdir=/tmp

[Tue May  2 11:19:43 2023]
Finished job 0.
2 of 2 steps (100%) done
Complete log: .snakemake/log/2023-05-02T111603.434282.snakemake.log
